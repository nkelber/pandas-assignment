{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/CC_BY.png\"><br />\n",
    "\n",
    "Created by [Nathan Kelber](http://nkelber.com) for\n",
    "Wayne State's Data Science Strategy and Leadership Course\n",
    "\n",
    "[Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "For questions/comments/improvements, email nathan.kelber@ithaka.org.<br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas Data Cleaning Assignment**\n",
    "\n",
    "The data is available at: https://data.detroitmi.gov/datasets/blight-violations/data in CSV format. The dataset has 482,497 rows and the file size is 225 mb in size. This is about half the maximum number of rows in Excel (1,048,576 rows). I recommend checking out the data in Excel before attempting to manipulate it in Pandas. The operations you will do for this assignment can all be executed in Excel, but learning to do them in Pandas will unlock a few benefits for your future work:\n",
    "\n",
    "* Pandas can operate on datasets that are much larger, millions of rows\n",
    "* Faster manipulations\n",
    "* Automating a series of transformations for new batches of data\n",
    "* Opening up advanced Pandas methods like regular expression matching, melts, and pivots that are difficult or impossible in Excel\n",
    "\n",
    "**Business Proposition**\n",
    "This assignment uses public data to discover possible clients for a snow removal business, but the methods could be used to locate clients in any number of fields. For example, the city of Detroit tracks data on [liquor licenses](https://data.detroitmi.gov/datasets/liquor-licenses/data?) which might be used to market liquor or security products. Some other datasets include:\n",
    "\n",
    "* [Licensed Professionals](https://data.detroitmi.gov/datasets/licensed-professionals)\n",
    "* [Restaurant Inspections](https://data.detroitmi.gov/datasets/restaurant-inspections)\n",
    "* [911 Calls for Service for the last 30 days](https://data.detroitmi.gov/datasets/911-calls-for-service-last-30-days-1)\n",
    "* [City Payments (Open Checkbook)](https://data.detroitmi.gov/datasets/open-checkbook-payments)\n",
    "* [Residential Demolitions](https://data.detroitmi.gov/datasets/completed-residential-demolitions/data?)\n",
    "\n",
    "How can you imagine this data might be useful to local businesses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Import Blight Data from the Detroit Open Data Portal\n",
    "\n",
    "Download the data from https://data.detroitmi.gov/datasets/blight-violations/data in CSV format. You can see the file structure of this Jupyter environment by using menu: \"File > Open\". Then choose upload to upload the document to the environment. \n",
    "\n",
    "Alternatively, you can use the library `urllib` to pull in the data automatically. The direct link to the CSV file is: https://opendata.arcgis.com/datasets/fe2f692918a04c13a6cead436e7eaec9_0.csv\n",
    "\n",
    "Can you adapt the code in the following cell to use that URL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://example.com/data.csv'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "open('Blight_Violations.csv', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening, Reading, and Writing CSV Files (.csv)\n",
    "CSV file data can be easily opened, read, and written using the `pandas` library. (For large CSV files (>500 mb), you may wish to use the `csv` library to read in a single row at a time to reduce the memory footprint.) Pandas is flexible for working with tabular data, and the process for importing and exporting to CSV is simple.\n",
    "\n",
    "Adapt the Pandas CSV read method below to our file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas \n",
    "import pandas as pd\n",
    "\n",
    "# Create our dataframe\n",
    "df = pd.read_csv('example_file.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm our data has been read in with `.shape` which gives us the number of rows and columns in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `.shape` to find rows and columns in the DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preview the first 10 rows in our dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the last 5 rows in our dataframe\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Drop Irrelevant Columns\n",
    "\n",
    "We are primarily interested in discovering where snow removal is an issue. There is a lot of data in this dataset that is not relevant to our analysis. First, let's drop all columns except:\n",
    "\n",
    "* ticket_id\n",
    "* violator_name\n",
    "* mailing_address_str_number\n",
    "* mailing_address_str_name\n",
    "* city\n",
    "* state\n",
    "* zip_code\n",
    "* violation_date\n",
    "* violation_address\n",
    "* violation_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the dataframe to certain columns\n",
    "df = df.loc[:, ['column_1', 'column_2', 'column_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the name of all columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Printing out the first five rows of the new dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Standardize the 'city' Column\n",
    "\n",
    "Our city column has a lot of variation in the names for cities. We can see that there are a ton of different city names. The next code cell shows how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of unique values in the city column\n",
    "unique_names = df['city'].unique()\n",
    "print(len(unique_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the scope of the problems by printing out our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(unique_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a problem of this magnitude, we could use libraries like FuzzyWuzzy and Levenshtein to do fuzzy text matching to an established list of Michigan cities. We could also use a tool like OpenRefine. That's beyond the scope of our assignment though. Let's just focus on fixing the entries for Detroit which is a challenge in itself with variations including:\n",
    "\n",
    "* 'Det'\n",
    "* 'DEt'\n",
    "* 'detroit'\n",
    "* 'DETROIT'\n",
    "* 'Detroit'\n",
    "* 'det'\n",
    "* 'det.'\n",
    "* 'DETRIT'\n",
    "* 'DETOIT'\n",
    "* 'Deroit'\n",
    "* 'Dertoit'\n",
    "\n",
    "By the way, you can [buy 'Dertroit Beisbolcats' athletic wear](https://www.beisbolcats.com/collections/all). We can do a create a filter here using regular expressions to clean up many problems by matching all strings that begin with 'det'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filter that matches 'det'\n",
    "detroit_filter = df['city'].str.contains('det', case=False, na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a filter, can you discover how to change the 4714 relevant values in the 'city' column to the string 'Detroit'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the relevant values in the 'city' column\n",
    "# To become 'Detroit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confirm the changes to the 'city' column\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Find all rows where 'violation_description' includes 'snow removal'\n",
    "\n",
    "We want to use the data in these blight violations to target business owners that could use a reliable snow removal service. Most of the violations here are not relevant for that purpose. Let's remove any that do no mention snow removal. Can you modify the next cell to our task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filter that will find snow removal violations\n",
    "snow_filter = df['column_name'].str.contains('string', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sum up the number of True values for snow_filter\n",
    "snow_filter.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the snow_filter to remove all non-relevant violations\n",
    "df = df[snow_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview our final, cleaned dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge: Create a full address column\n",
    "This challenge is not required for full credit but can you use the data from these columns:\n",
    "\n",
    "* violator_name\n",
    "* mailing_address_str_number\n",
    "* mailing_address_str_name\n",
    "* city\n",
    "* state\n",
    "* zip_code\n",
    "\n",
    "to create a new column called 'mailing_address' so that each violator's address could easily be printed onto a snow removal service brochure that would be sent by mail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Output Your Cleaned Data\n",
    "\n",
    "After you've made any necessary changes in Pandas, write the dataframe back to the CSV file. (Remember to always back up your data before writing over the file.) Update the file name here to describe your final, cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to new file\n",
    "# Keeping the Header but removing the index\n",
    "df.to_csv('your_file_name.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning in your Notebook\n",
    "Download an HTML version of your notebook from the file menu (File > Download as > HTML (.html). Send the file to Professor Kelber in an email (nkelber@gmail.com) or through Canvas. Make sure you have successfully run all the code cells in the notebook. You do not need to send your CSV output file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
